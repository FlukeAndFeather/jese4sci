# VAL101: You've got bugs

## Learning goals

1.  Understand that all non-trivial code has bugs
2.  Describe the strategies software engineers use to minimize (not eliminate) bugs

## The broken binary search

Any Introduction to Algorithms course (i.e., "how to think like a computer scientist" CS102 type courses) will teach the binary search algorithm. It's a conceptually simple, highly efficient method for finding where an element is in a sorted list. Given `x = c(1, 3, 9, 11)` (a sorted list), `binary_search(9)` would return 3 (the index of 9 in `x`). That is, if `binary_search()` was an R function. But hopefully you get the idea.

So why does a track about validating your code begin with a description of one of the most elementary computer science algorithms? Because in 2004, 58 years after the algorithm was first published and 8 years after Java was written, it was discovered that the official Java implementation of binary search had a [bug in it](https://bugs.java.com/bugdatabase/view_bug.do?bug_id=5045582). Now granted, this bug only occurred for massive lists. To encounter the bug your list would have to be almost as long as the maximum integer Java can represent (in 2004, about 2^31). So if there could be a bug in one of the most basic functions of one of the most prevalent programming languages in the world, and if that bug could persist for nearly a decade, more than half a century after the algorithm was written, then _you can sure as hell bet your code has bugs in it_.

Therefore, the question is not "how can I make sure my code doesn't have bugs?" That's a fool's errand. The better question is "how do I minimize the number of bugs?" An even more important question, especially in science where we're tackling hard questions with evolving requirements, is "how do I keep from re-introducing old bugs when I make code changes?"

## Tools of the trade

In this track, you'll learn three valuable techniques that can increase confidence in code accuracy. In VAL102, you'll learn how to anticipate errors using _defensive programming_. VAL201 introduces _unit tests_. Unit tests may seem like a logistical nightmare to many scientists, but one of the many benefits of using the research compendium framework (and underlying R package structure) is you'll have access to the testthat package, which makes unit testing easy. You can even set up [GitHub Actions](https://github.com/features/actions) to run your unit tests every time you push changes, and you'll get an email report notifying you of any new failures. But knowing you have an error is only the start when it comes to diagnosing and fixing bugs, so in VAL202 you'll learn advanced debugging techniques. Most importantly, you'll learn how to write a _minimal reproducible example_ (AKA reprex), which is the simplest piece of code that triggers the bug. Oftentimes, you'll find that the very act of producing the reprex is enough to solve the issue.

## Submit assignment

Open an issue in [FlukeAndFeather/jese4sci-VAL](https://github.com/FlukeAndFeather/jese4sci-VAL). Put "VAL101" in the title. In the comment, answer the following questions.

1.  How do you check that your code works? 
2.  Pick an R package you use frequently. Find an issue associated with a fixed bug. For example, here's an [issue](https://github.com/plotly/plotly.R/issues/1870) for a bug in plotly with x-axis dates. Hint: you'll have to search for closed issues. Regarding your issue:
    1.  Summarize the bug
    2.  Was there a conversation about what caused the bug or how to fix it?
    3.  How many lines of code changed in the fix? Hint: look for an entry that says "[username]  pushed a commit that referenced this issue..."
